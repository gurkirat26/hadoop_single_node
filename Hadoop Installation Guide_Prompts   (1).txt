Installation of Hadoop
1. Install java
2. Go to  Oracle java -> java se dev kit-> java 8
3. Login with  java id nsut id and normal password with cap first letter
4. Make java folder in c drive
5. Run the exe file
6. Change path to c:\Java and install
7. Progam files ->Java-> copy jrd folder and paste in Java folder in c drive
8. Delete program files Java folder
9. Edit environment var
10. New JAVA_HOME-> path of jrd bin in value->close
11. System variables mai also put these path
12. Open cmd and check
Hadoop Download
1. Go to apache hadoop ->download->3.2.4-> binary and start downloading
2. Extract the folder to the c drive
3. Rename folder as hadoop
4. hadoop->etc->hadoop->hadoop.env.cmd
5. Paste in %JAVA_HOME% ke jrd ka path same as above
6. Edit env var-> HADOOP_HOME-> c:\hadoop\bin
7. In system vars add this and \sbin
Configure Hadoop
1. Hadoop ->etc->hadoop->core xml->edit
2. Write these commands
3. <configuration>
4. <property>
5. <name>fs.defaultFS</name>
6. <value>hdfs://localhost:9000</value>
7. </property>
8. </configuration>
9. Now go to httpfs-site.xml file and write the following commands
10.  <configuration>
11. <property>
12. <name>dfs.replication</name>
13. <value>1</value>
14. </property>
15. <property>
16. <name>dfs.namenode.name.dir</name>
17. <value>C:\hadoop\data\namenode</value>
18. </property>
19. <property>
20. <name>dfs.datanode.data.dir</name>
21. <value>C:\hadoop\data\datanode</value>
22. </property>
23. </configuration>
24. hadoop -> create folder named data
25. Inside data create 2 more folders namenode and datanode
26.  Now again hadoop->etc->hadoop->mapred-site.xml
27. Write these commands under configuration
28. <property>
29. <name>mapreduce.framework.name</name>
30. <value>yarn</value>
31. </property>
32.  Lastly Now again hadoop->etc->hadoop->yarn-site.xml
33. Write these commands
34. <property>
35. <name>yarn.nodemanager.aux-services</name>
36. <value>mapreduce_shuffle</value>
37. </property>
38. <property>
39. <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>
40. <value>org.apache.hadoop.mapred.shuffleHandler</value>
41. </property>
42. Delete the bin folder
43. Now download the folder from this link
44. https://drive.google.com/file/d/1nCN_jK7EJF2DmPUUxgOggnvJ6k6tksYz/view
45. Now download the msvcr120.dll file
46. Now paste this dll file in the windows32 folder
47. download the msvc 170
48. In cmd as admin write Hdfs namenode -format
49. Now cd over to hadoop
50. hadoop->sbin
51. Write start-dfs.cmd
52. Name node and data node should start working
53. Jps to show state
54. Start-yarn.cmd
55. Jps all 4 demons running
56. Localhost:9870
57. Localhost:8088
58.  For more details 
59. https://towardsdatascience.com/installing-hadoop-3-2-1-single-node-cluster-on-windows-10-ac258dd48aef